{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35bd3585-a08a-4322-9e7e-5f5a5dfaf060",
   "metadata": {},
   "source": [
    "# ENTRENAMIENTO MODELO IA / ¿SPAM o NO SPAM?\n",
    "\n",
    ">En esta ocasión, estaremos entrenando un modelo de IA capaz de detectar cuando un correo es o no es SPAM, usaremos temporalmente un dataset en formato CSV pequeño para ver su comportamiento y utilizando por primera vez tecnologías como:\n",
    ">Jupyter\n",
    ">Pandas\n",
    ">Matplot\n",
    ">Sklearn\n",
    ">Pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8de6578-eb03-4be6-bb3b-403b3b83e30c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 1 – Cargar los datos\n",
    "\n",
    "En esta sección vamos a cargar el CSV con pandas para inspeccionar el dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264f24d3-0be1-44ff-9466-fbc5b7febc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free money now!!!</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi, how are you?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Win a brand new car</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are we still on for lunch?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Call now to claim your prize</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           text label\n",
       "0             Free money now!!!  spam\n",
       "1              Hi, how are you?   ham\n",
       "2           Win a brand new car  spam\n",
       "3    Are we still on for lunch?   ham\n",
       "4  Call now to claim your prize  spam"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Cargar el CSV con el dataset\n",
    "df = pd.read_csv(\"spam_dataset.csv\")\n",
    "\n",
    "#Mostrar las primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2691cc81-14bf-43b1-ac4c-7cb3a3030809",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 2 - Convertir 'spam' y 'ham' en 1's y 0's respectivamente\n",
    "Lo haremos para el entrenamiento del modelo y para ayudarnos para vectorizar nuestro dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6487caff-bcae-4d0a-ac2a-5126d8b2ba28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free money now!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi, how are you?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Win a brand new car</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are we still on for lunch?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Call now to claim your prize</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           text  label\n",
       "0             Free money now!!!      1\n",
       "1              Hi, how are you?      0\n",
       "2           Win a brand new car      1\n",
       "3    Are we still on for lunch?      0\n",
       "4  Call now to claim your prize      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertir etiquetas a números\n",
    "df['label'] = df['label'].map({'ham' : 0, 'spam' : 1})\n",
    "\n",
    "#Verificamos que se haya conseguido correctamente\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165ffb3-20e7-4d7b-abf7-ac5f94b42623",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 3 - Separamos los nombres de las etiquetas\n",
    "Tendremos mayor orden y control sobre los datos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f7706c-29da-4152-9ad1-935fe358ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text'] #Los mensajes\n",
    "y = df['label'] #Etiquetas (0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e773291-6ed4-4c33-bf6d-ca0ba1b735e2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 4 - Dividiremos el dataset en training set (80%) y testing set (20%) \n",
    "Esto para probar que el modelo tenga ejemplos para referenciarse y luego probar la detección con otros ejemplos que no haya visto nunca. En caso que utilicemos datos de más y el modelo solo esté memorizando. Obtendremos un problema comúnmente conocido como **Overfitting**.\n",
    "\n",
    "Para poder dividir el dataset utilizaremos ```train_test_split```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29630cb0-5d3b-451a-883d-fc5b82ec9ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Dividimos el dataset en las proporciones mencionadas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7528fb4-1287-4a96-a847-74de546cb9f6",
   "metadata": {},
   "source": [
    "**Nota**: El ```random_state=42``` significa: “Usá esta semilla aleatoria fija para que la división entre train y test sea siempre igual cada vez que ejecuto el código.”\n",
    "\n",
    "Esto es así puesto que si no lo colocamos, cada vez que se corra el código, los datos se **dividen distinto**, porque el proceso es aleatorio.\n",
    "Eso hace que los resultados cambien y sean difíciles de reproducir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2644e6e3-d428-45dc-a481-e2c15042d1f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 5 - Vectorizar los mensajes\n",
    "**Pytorch** por defecto no entiende textos, solo **Tensores**, una estructura matemática que hace todo posible en la Inteligencia Artifical. Asi que utilizaremos Scikit Learn para poder vectorizar la información y prepararla para poder llevarla a Tensores\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b204c83e-b810-4e35-8a51-0a9b2557882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Creando el vectorizador\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "#Aprender a partir de texto y pasarlo a vectores\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed306aa-099f-485a-ad67-00b0838776c3",
   "metadata": {},
   "source": [
    "### ¿Qué hace esto?\n",
    "\n",
    "Crea una \"bolsa de palabras\": cada palabra es una columna.\n",
    "\n",
    "Cada mensaje se transforma en un vector que cuenta cuántas veces aparece cada palabra.\n",
    "\n",
    "El resultado es una matriz dispersa (sparse matrix) como esta:\n",
    "\n",
    "```[0 1 0 0 3 0 0 2 ...]```\n",
    "\n",
    "Cada número representa la **frecuencia** de una palabra en ese mensaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ec05c-03be-49ba-a14c-338c684ded4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 6 - Conversión Tensorial y preparar el dataLoader\n",
    "Una vez vectorizado el dataset, podemos pasarlos a tensores para trabajar con pytorch sin problemas, además de agregar el **dataLoader**, cuyo funcionamiento es cargar automáticamente los datos a Pytorch, sin necesidad de ir uno por uno.\n",
    "\n",
    "- Este proceso consiste en dividir en lotes (batchs) equitativos de datos:\n",
    "\n",
    "\n",
    "  Ejemplo: Si tenemos un dataset de 800 elementos, y el lote es de 16 datos cada uno, tendremos 50 lotes, 16x50 = 800.\n",
    "\n",
    "  \n",
    "- Permite hacer **shuffle**, es decir, mezclar los datos para que no sea siempre lo mismo.\n",
    "\n",
    "- Y también nos facilita el trabajo con datasets grandes, para no saturar la memoria, podemos ir pasando por lotes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe5ccab6-3951-439b-813c-3476493d52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#Convertimos todos los vectores en Tensores y los pasamos como flotantes\n",
    "X_train_tensor = torch.tensor(X_train_vect.toarray()).float()\n",
    "X_test_tensor = torch.tensor(X_test_vect.toarray()).float()\n",
    "y_train_tensor = torch.tensor(y_train.values).float()\n",
    "y_test_tensor = torch.tensor(y_test.values).float()\n",
    "\n",
    "# Dataset y DataLoader\n",
    "BATCH_SIZE = 16\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bd1be5-fca7-4d8a-98ff-7a1689deb12e",
   "metadata": {},
   "source": [
    "**Nota:**\n",
    "\n",
    "```.toarray()``` convierte la matriz dispersa en una común para que PyTorch pueda leerla\n",
    "\n",
    "```float()``` es porque vamos a usar redes neuronales que trabajan con números reales\n",
    "\n",
    "```TensorDataset``` empaqueta entradas y etiquetas\n",
    "\n",
    "```DataLoader``` reparte los datos en mini-lotes (batches) y los mezcla (shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81efe1-a26a-47db-a183-b090e5d7e6fa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 7 - Crear el Modelo con Pytorch\n",
    "Crearemos en esta ocasión una red neuronal de Clasificación Binaria simple, ideal para nuestro caso\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8417a552-f158-4584-b994-61c650a891f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Definimos arquitectura del modelo mediante clases\n",
    "class SpamClassifier(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super(SpamClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim,16) #Capa oculta conectada con 16 neuronas\n",
    "        self.fc2 = nn.Linear(16,1) #Capa de Salida con 1 neurona, define probabilidad final\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x)) #Activación ReLU\n",
    "        x = torch.sigmoid(self.fc2(x)) #Activación sigmoide para conversión a valor entre 0 y 1\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd46d0-5651-45c6-a3dc-945d8403b109",
   "metadata": {},
   "source": [
    "## Arquitectura del modelo\n",
    "Definimos una clase **SpamClassifier** que hereda de nn.Module, lo que le dice a PyTorch que es un modelo entrenable.\n",
    "\n",
    "Dentro de esa clase:\n",
    "\n",
    "### __init__:\n",
    "\n",
    "Es el constructor, y ahí definimos las capas del modelo.\n",
    "\n",
    "Es como declarar: **“quiero una capa de entrada con tantas neuronas (input_dim), una oculta con 16, y una de salida con 1”.**\n",
    "\n",
    "self.fc1 y self.fc2 son esas capas **(fully connected)**.\n",
    "\n",
    "Con super, podemos llamar al constructor de la clase padre **nn.module** para que pueda manejar las capas correctamente\n",
    "\n",
    "### forward:\n",
    "\n",
    "Define cómo viajan los datos a través de la red.\n",
    "\n",
    "Pasa primero por la capa fc1, le aplica una **ReLU** - Rectified Linear Unit o Unidad Lineal Rectificada (para que aprenda no linealidades), toma el valor absoluto de la información, haciendo siempre positivo o 0 el resultado\n",
    "\n",
    "Luego pasa por la capa fc2, y se le aplica una **sigmoide** (para que la salida sea entre 0 y 1, útil para clasificación binaria).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b282a033-f373-40d3-b653-4c6799fef337",
   "metadata": {},
   "source": [
    "### Instanciando el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2e078ea-3493-422c-b760-e0067b7c8b34",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_11043/3394436265.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m input_dim = X_train.tensor.shape[\u001b[32m1\u001b[39m] \u001b[38;5;66;03m#Definimos el tamaño de la capa de Entrada\u001b[39;00m\n\u001b[32m      2\u001b[39m model = SpamClassifier(input_dim) \u001b[38;5;66;03m#Instanciamos el modelo con la arquitectura \"SpamClassifier\" y el tamaño\u001b[39;00m\n",
      "\u001b[32m~/Documents/Projects/spam-clasificator/venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6314\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6315\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6316\u001b[39m         ):\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6318\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Series' object has no attribute 'tensor'"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_tensor.shape[1] #Definimos el tamaño de la capa de Entrada\n",
    "model = SpamClassifier(input_dim) #Instanciamos el modelo con la arquitectura \"SpamClassifier\" y el tamaño"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f872f86-dc5c-4d85-a283-452ed6fa6a84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 8 - Definir función de perdida y optimizador\n",
    "\n",
    "En este paso nos aseguramos que el modelo realmente vaya aprendiendo a medida que pasen las epochs o ciclos de aprendizaje, una vez que haya hecho la primer epoch, tenemos que fijarnos en la funcion de perdida (error) y ver cuanto tenemos que ajustar estos hiperparámetros para que el modelo mejore a medida que vayan pasando los ciclos de fit.\n",
    "\n",
    "Para la función de perdida (**LOSS**) utilizaremos **BCELoss o Binary Cross Entropy**:\n",
    "\n",
    "Compara la predicción (probabilidad entre 0 y 1) con la etiqueta real (0 o 1) y mide qué tan mal estamos.\n",
    "\n",
    "Para el optimizador utilizaremos **Adam**, un Algoritmo de optimización ideal para nuestro caso, para el ajuste de pesos de la red neuronal\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21e2d11c-0333-4ba1-91fb-86460ec6c94b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m criterion = nn.BCELoss()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#Optimizador\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m optimizer = optim.Adam(\u001b[43mmodel\u001b[49m.parameters(), lr=\u001b[32m0.001\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#Función de pérdida o LOSS\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "#Optimizador\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
